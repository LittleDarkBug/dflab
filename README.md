# DataFlowLab


# Plateforme Visuelle de Pipelines Machine Learning

DataFlowLab est une application Python locale et modulaire permettant aux data scientists de cr√©er visuellement des pipelines ML par drag-and-drop, avec EDA automatis√©e, g√©n√©ration de code et assistance par LLM local.

## Fonctionnalit√©s

- Construction visuelle de pipelines : Interface drag-and-drop intuitive
- EDA automatique : Analyse exploratoire intelligente avec insights
- Assistant LLM local : Aide contextuelle sans d√©pendance externe
- G√©n√©ration de code : Export Python/Jupyter ex√©cutable
- Plus de 40 blocs ML : Biblioth√®que compl√®te pour tous types de projets
- Sauvegarde/chargement : Projets persistants et r√©utilisables

## Installation

### Pr√©requis

- Python 3.11+
- Gestionnaire de packages pip

### Installation rapide


1. Cloner le projet :

```bash
git clone <repo-url>
cd dataflowlab
```


2. Cr√©er un environnement virtuel :

```bash
# Avec conda (recommand√©)
conda create -n dataflowlab python=3.11
conda activate dataflowlab

# Ou avec venv
python -m venv dataflowlab
# Windows
dataflowlab\Scripts\activate
# Linux/Mac
source dataflowlab/bin/activate
```


3. Installer les d√©pendances :

```bash
pip install -r requirements.txt
```



4. V√©rifier l'installation :

Il n'y a plus de script de test rapide universel. Pour v√©rifier l'installation, lancez simplement l'application ou ex√©cutez les tests unitaires :

```bash
python -m dataflowlab.ui.app
# ou
pytest tests/
```


## Lancement de l'application

```bash
python -m dataflowlab.ui.app
```

L'interface Gradio sera accessible √† : `http://localhost:7860`

## Utilisation



### 1. Construction et ex√©cution d‚Äôun pipeline

#### Workflow utilisateur

1. S√©lection d‚Äôun bloc : Cliquez sur un bloc dans la biblioth√®que (aucun ajout automatique).
2. Configuration : Les param√®tres du bloc s‚Äôaffichent dynamiquement dans le panneau lat√©ral (ex : fichier √† charger, s√©parateur, options avanc√©es).
3. Ajout explicite : Cliquez sur ¬´ Ajouter au pipeline ¬ª pour ins√©rer le bloc dans le workflow.
4. R√©organisation : Glissez-d√©posez pour r√©ordonner les blocs si besoin.
5. Ex√©cution : Cliquez sur ¬´ Ex√©cuter Pipeline ¬ª pour lancer le traitement s√©quentiel (chaque bloc applique sa m√©thode `process`).
6. Visualisation : Les r√©sultats interm√©diaires et finaux s‚Äôaffichent, les erreurs sont expliqu√©es clairement.

#### Conseils

- Aucun bloc n‚Äôest ajout√© sans action explicite.
- Les param√®tres sont adapt√©s √† chaque bloc (data_input, mod√®les, etc.).
- Les erreurs de type, de format ou de d√©pendance sont g√©r√©es et affich√©es √† l‚Äôutilisateur.

#### Sch√©ma du workflow (texte)

S√©lection bloc ‚Üí Configuration ‚Üí Ajout pipeline ‚Üí R√©organisation ‚Üí Ex√©cution ‚Üí R√©sultats/Export

### 2. Types de blocs disponibles

Voir la section d√©taill√©e plus bas pour la liste compl√®te (Data Input, Cleaning, Feature Engineering, Supervised, Unsupervised, Evaluation, Timeseries, Advanced).

### 3. Gestion avanc√©e des param√®tres

- Chaque bloc propose des champs de configuration dynamiques (texte, nombre, select, fichier, etc.).
- Les blocs data_input permettent la s√©lection de fichiers, le choix du s√©parateur, l‚Äôencodage, etc.
- Les blocs avanc√©s proposent des options expertes accessibles.

### 4. Gestion des erreurs et robustesse

- Les erreurs de configuration, de format de fichier ou de d√©pendance sont intercept√©es et expliqu√©es.
- Les messages d‚Äôinterface guident l‚Äôutilisateur √† chaque √©tape.

### 5. Export, sauvegarde et assistant LLM

- Export Python/Jupyter, sauvegarde/chargement JSON, assistant LLM local pour l‚Äôaide contextuelle.

### 6. FAQ

Q : Pourquoi mon bloc n‚Äôappara√Æt pas ?
A : V√©rifiez qu‚Äôil h√©rite bien de `BlockBase`, qu‚Äôil est enregistr√© dans le `BlockRegistry` et qu‚Äôil impl√©mente la m√©thode `process`.

Q : J‚Äôai une erreur ‚Äúd√©pendance manquante‚Äù ?
A : Installez le package requis (voir la section D√©pendances). Certains blocs avanc√©s n√©cessitent `statsmodels`, `shap`, etc.

Q : Comment corriger une erreur de type ou de format ?
A : V√©rifiez la configuration du bloc, le type de fichier ou le format des donn√©es d‚Äôentr√©e.


## Structure du projet


```
dataflowlab/
‚îú‚îÄ‚îÄ core/                 # Syst√®me central
‚îÇ   ‚îú‚îÄ‚îÄ block_base.py
‚îÇ   ‚îú‚îÄ‚îÄ block_registry.py
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py
‚îú‚îÄ‚îÄ blocks/               # Biblioth√®que de blocs ML
‚îÇ   ‚îú‚îÄ‚îÄ advanced/
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning/
‚îÇ   ‚îú‚îÄ‚îÄ data_input/
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering/
‚îÇ   ‚îú‚îÄ‚îÄ supervised/
‚îÇ   ‚îú‚îÄ‚îÄ timeseries/
‚îÇ   ‚îî‚îÄ‚îÄ unsupervised/
‚îú‚îÄ‚îÄ eda/
‚îÇ   ‚îú‚îÄ‚îÄ auto_eda.py
‚îÇ   ‚îî‚îÄ‚îÄ report_exporter.py
‚îú‚îÄ‚îÄ export/
‚îÇ   ‚îú‚îÄ‚îÄ exporter.py
‚îÇ   ‚îî‚îÄ‚îÄ notebook_exporter.py
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îî‚îÄ‚îÄ assistant.py
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îî‚îÄ‚îÄ dragdrop_blocks.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ errors.py
‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îî‚îÄ‚îÄ __init__.py
tests/
‚îú‚îÄ‚îÄ test_association_rules.py
‚îú‚îÄ‚îÄ test_auto_eda.py
‚îú‚îÄ‚îÄ test_block_base.py
‚îú‚îÄ‚îÄ test_csv_loader.py
‚îú‚îÄ‚îÄ test_dragdrop_blocks.py
‚îú‚îÄ‚îÄ test_llm_assistant.py
‚îú‚îÄ‚îÄ test_notebook_exporter.py
‚îú‚îÄ‚îÄ test_pipeline.py
‚îî‚îÄ‚îÄ test_pipeline_integration.py
sample_data.csv
requirements.txt
README.md
DEVELOPER_GUIDE.md
```

## D√©veloppement

### Ajouter un nouveau bloc

1. **Cr√©er la classe** dans le module appropri√© :
```python
from dataflowlab.core.block_base import BlockBase
from dataflowlab.core.block_registry import BlockRegistry

class MonNouveauBloc(BlockBase):
    def process(self, data, **kwargs):
        # Votre logique ici
        return data_transformee
    
    def get_config_fields(self):
        return [
            {
                "name": "param1",
                "type": "number",
                "label": "Mon param√®tre",
                "default": 0
            }
        ]

# Enregistrement automatique
BlockRegistry.register("MonNouveauBloc", MonNouveauBloc, "ma_categorie")
```

2. **Ajouter aux imports** dans `__init__.py` du module


3. **Tester** avec `pytest tests/`

### Tests

```bash
# Lancer tous les tests unitaires
pytest tests/
```

## D√©pendances

### Obligatoires
- `gradio>=4.0` : Interface utilisateur
- `pandas>=2.0` : Manipulation donn√©es
- `numpy>=1.24` : Calcul num√©rique
- `scikit-learn>=1.3` : Machine learning
- `plotly>=5.0` : Visualisations

### Optionnelles
- `statsmodels>=0.14` : Statistiques avanc√©es
- `xgboost>=2.0` : Gradient boosting
- `lightgbm>=4.0` : Gradient boosting
- `llama-cpp-python>=0.2.72` : LLM local
- `shap>=0.44` : Explainability

## Contribution

1. Fork le projet
2. Cr√©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Cr√©er une Pull Request

## Licence

Ce projet est distribu√© sous licence GPLv3. Voir le fichier `LICENSE` pour plus de d√©tails.

## Support

- üìö Documentation compl√®te : `DEVELOPER_GUIDE.md`
- üêõ Issues : GitHub Issues
- üí¨ Discussions : GitHub Discussions

---

**DataFlowLab** - D√©mocratiser le Machine Learning par la simplicit√© visuelle.
